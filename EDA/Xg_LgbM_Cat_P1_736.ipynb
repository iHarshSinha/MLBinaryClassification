{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502d2820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from '..\\data\\train.csv' and '..\\data\\test.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "TRAIN_PATH = os.path.join('..', 'data', 'train.csv')\n",
    "TEST_PATH = os.path.join('..', 'data', 'test.csv')\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_PATH)\n",
    "    test_df = pd.read_csv(TEST_PATH)\n",
    "    print(f\"Successfully loaded data from '{TRAIN_PATH}' and '{TEST_PATH}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Files not found. Ensure 'train.csv' and 'test.csv' are located at the path: {os.path.abspath(os.path.join(os.getcwd(), '..', 'data'))}\")\n",
    "    exit()\n",
    "\n",
    "# Isolate the founder_id for the submission file\n",
    "test_ids = test_df['founder_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d414b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Applies the specified feature engineering steps.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Create Age at Founding\n",
    "    df['age_at_founding'] = df['founder_age'] - df['years_since_founding']\n",
    "\n",
    "    # Create Founder Tenure Ratio\n",
    "    epsilon = 1e-6\n",
    "    df['tenure_ratio'] = df['years_with_startup'] / (df['years_since_founding'] + epsilon)\n",
    "    \n",
    "    # Create proxy for 'unhappy' and 'overtime' interaction\n",
    "    df['unhappy_overtime'] = (df['working_overtime'] == 'Yes').astype(int) * \\\n",
    "                             (df['venture_satisfaction'].map({'Low': 1, 'Medium': 0.5, 'High': 0, 'Very High': 0}))\n",
    "    \n",
    "    # Drop the ID column\n",
    "    return df.drop('founder_id', axis=1, errors='ignore')\n",
    "\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "# Target Encoding: Left=1, Stayed=0\n",
    "train_df['retention_status'] = train_df['retention_status'].map({'Left': 1, 'Stayed': 0})\n",
    "\n",
    "X = train_df.drop('retention_status', axis=1)\n",
    "y = train_df['retention_status']\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f898594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.1 Define Feature Lists and Ordinal Maps ---\n",
    "numerical_features = ['founder_age', 'years_with_startup', 'monthly_revenue_generated', \n",
    "                      'funding_rounds_led', 'distance_from_investor_hub', \n",
    "                      'num_dependents', 'years_since_founding', 'age_at_founding', \n",
    "                      'tenure_ratio', 'unhappy_overtime']\n",
    "\n",
    "# Define categories and their order\n",
    "ordinal_mappings = [\n",
    "    ('work_life_balance_rating', ['Poor', 'Fair', 'Good', 'Excellent', 'Missing']),\n",
    "    ('venture_satisfaction', ['Low', 'Medium', 'High', 'Very High', 'Missing']),\n",
    "    ('startup_performance_rating', ['Below Average', 'Low', 'Average', 'High', 'Excellent']),\n",
    "    ('startup_reputation', ['Low', 'Moderate', 'High', 'Excellent']),\n",
    "    ('founder_visibility', ['Low', 'Medium', 'High', 'Very High'])\n",
    "]\n",
    "ordinal_cols = [col for col, _ in ordinal_mappings]\n",
    "ordinal_categories = [order for _, order in ordinal_mappings]\n",
    "\n",
    "nominal_cols = ['founder_gender', 'founder_role', 'working_overtime', \n",
    "                'education_background', 'personal_status', \n",
    "                'startup_stage', 'team_size_category', \n",
    "                'remote_operations', 'leadership_scope', 'innovation_support']\n",
    "\n",
    "\n",
    "# --- 3.2 Define Preprocessing Steps ---\n",
    "\n",
    "# 1. Numerical Pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 2. Ordinal Pipeline (Impute 'Missing', then Ordinal Encode)\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='Missing', missing_values=np.nan)),\n",
    "    ('ordinal', OrdinalEncoder(categories=ordinal_categories, handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# 3. Nominal Pipeline (One-Hot Encode)\n",
    "nominal_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "\n",
    "# --- 3.3 Create Column Transformer ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('ord', ordinal_transformer, ordinal_cols),\n",
    "        ('nom', nominal_transformer, nominal_cols)\n",
    "    ],\n",
    "    remainder='drop', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on training data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bcdd235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5-Fold Cross-Validation for Threshold Optimization...\n",
      "\n",
      "--- F1 Optimization Results ---\n",
      "Optimal Threshold: 0.3354\n",
      "Maximized F1-Score (OOF): 0.7509\n",
      "\n",
      "Confusion Matrix (OOF - predicting 'Left' as 1):\n",
      "[[18806 12459]\n",
      " [ 3816 24530]]\n",
      "\n",
      "Training final model on full dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ayush Mishra\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- 4.1 Define Model ---\n",
    "lgbm_clf = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    metric='None',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# --- 4.2 Cross-Validation for Threshold Optimization ---\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Performing 5-Fold Cross-Validation for Threshold Optimization...\")\n",
    "oof_probas = cross_val_predict(\n",
    "    lgbm_clf,\n",
    "    X_processed,\n",
    "    y,\n",
    "    cv=skf,\n",
    "    method='predict_proba',\n",
    "    n_jobs=-1\n",
    ")[:, 1]\n",
    "\n",
    "# --- 4.3 Optimize Classification Threshold ---\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# Function to minimize (negative F1-score)\n",
    "def objective_f1(threshold):\n",
    "    y_pred_binary = (oof_probas >= threshold).astype(int)\n",
    "    return -f1_score(y, y_pred_binary)\n",
    "\n",
    "# Scalar bounded minimization\n",
    "result = minimize_scalar(\n",
    "    objective_f1,\n",
    "    bounds=(0.01, 0.99),\n",
    "    method='bounded',\n",
    "    options={'xatol': 1e-5}\n",
    ")\n",
    "\n",
    "optimal_threshold = result.x\n",
    "optimal_f1 = -result.fun\n",
    "\n",
    "print(f\"\\n--- F1 Optimization Results ---\")\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Maximized F1-Score (OOF): {optimal_f1:.4f}\")\n",
    "\n",
    "# Sanity Check: Print Confusion Matrix at Optimal Threshold\n",
    "y_pred_optimal = (oof_probas >= optimal_threshold).astype(int)\n",
    "print(\"\\nConfusion Matrix (OOF - predicting 'Left' as 1):\")\n",
    "print(confusion_matrix(y, y_pred_optimal))\n",
    "\n",
    "# --- 4.4 Final Model Training and Prediction ---\n",
    "print(\"\\nTraining final model on full dataset...\")\n",
    "final_model = lgbm_clf.fit(X_processed, y)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "test_probas = final_model.predict_proba(X_test_processed)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41015680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Optimal Threshold: 0.3354\n",
      "\n",
      "--- FINAL SUBMISSION CREATED ---\n",
      "File: 'lgbm_f1_hard_labels_submission_final.csv'\n",
      "First 5 rows of the submission:\n",
      "   founder_id retention_status\n",
      "0       52685             Left\n",
      "1       30585             Left\n",
      "2       54656           Stayed\n",
      "3       33442             Left\n",
      "4       15667           Stayed\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Submission File Creation with Hard Labels (Corrected) ---\n",
    "\n",
    "# 1. Use the optimal threshold found in Section 4.3\n",
    "# CORRECTED LINE: Access result.x directly, as it is likely a scalar\n",
    "optimal_threshold = result.x \n",
    "\n",
    "# Ensure it's a standard float for comparison, if necessary (good practice)\n",
    "if isinstance(optimal_threshold, np.ndarray):\n",
    "    optimal_threshold = optimal_threshold[0]\n",
    "    \n",
    "print(f\"Using Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "\n",
    "# 2. Convert the predicted probabilities (test_probas) into hard labels\n",
    "# If probability >= optimal_threshold, predict 'Left' (the positive class, 1)\n",
    "# If probability < optimal_threshold, predict 'Stayed' (the negative class, 0)\n",
    "hard_labels = np.where(test_probas >= optimal_threshold, 'Left', 'Stayed')\n",
    "\n",
    "# 3. Create the submission DataFrame\n",
    "submission_df_final = pd.DataFrame({\n",
    "    'founder_id': test_ids,\n",
    "    'retention_status': hard_labels \n",
    "})\n",
    "\n",
    "# 4. Save the submission file\n",
    "submission_df_final.to_csv('lgbm_f1_hard_labels_submission_final.csv', index=False, encoding='utf-8', sep=',')\n",
    "\n",
    "print(\"\\n--- FINAL SUBMISSION CREATED ---\")\n",
    "print(f\"File: 'lgbm_f1_hard_labels_submission_final.csv'\")\n",
    "print(\"First 5 rows of the submission:\")\n",
    "print(submission_df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f952bb4",
   "metadata": {},
   "source": [
    "Trying Catboost+Xg+Lgb\n",
    " run these after preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd # Assuming test_ids and test_probas from LGBM are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b55368",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Training XGBoost Model ---\")\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2.1. Train\n",
    "xgb_clf.fit(X_processed, y)\n",
    "\n",
    "# 2.2. Predict Probabilities\n",
    "xgb_test_probas = xgb_clf.predict_proba(X_test_processed)[:, 1]\n",
    "print(\"XGBoost Test Predictions Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05acb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training CatBoost Model ---\")\n",
    "\n",
    "cb_clf = cb.CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3,\n",
    "    loss_function='Logloss',\n",
    "    verbose=0, # Suppress training output\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3.1. Train\n",
    "cb_clf.fit(X_processed, y)\n",
    "\n",
    "# 3.2. Predict Probabilities\n",
    "cb_test_probas = cb_clf.predict_proba(X_test_processed)[:, 1]\n",
    "print(\"CatBoost Test Predictions Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a873207",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Generate XGB OOF predictions\n",
    "xgb_oof_probas = cross_val_predict(\n",
    "    xgb_clf, \n",
    "    X_processed, \n",
    "    y, \n",
    "    cv=skf, \n",
    "    method='predict_proba', \n",
    "    n_jobs=-1\n",
    ")[:, 1]\n",
    "\n",
    "# Generate CB OOF predictions\n",
    "cb_oof_probas = cross_val_predict(\n",
    "    cb_clf, \n",
    "    X_processed, \n",
    "    y, \n",
    "    cv=skf, \n",
    "    method='predict_proba', \n",
    "    n_jobs=-1\n",
    ")[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. Create Ensemble OOF Probability\n",
    "# Note: oof_probas is from your original LGBM run\n",
    "ensemble_oof_probas = (oof_probas + xgb_oof_probas + cb_oof_probas) / 3.0\n",
    "\n",
    "# 4.2. Optimize Classification Threshold for the Ensemble\n",
    "\n",
    "# The objective function remains the same\n",
    "def objective_f1_ensemble(threshold):\n",
    "    \"\"\"Returns negative F1-score for minimization.\"\"\"\n",
    "    y_pred_binary = (ensemble_oof_probas >= threshold).astype(int)\n",
    "    return -f1_score(y, y_pred_binary)\n",
    "\n",
    "# CORRECTED: Change method='bounded' to method='L-BFGS-B' \n",
    "result_ensemble = minimize(\n",
    "    objective_f1_ensemble, \n",
    "    x0=0.5,             \n",
    "    method='L-BFGS-B',   # Corrected Solver Name\n",
    "    bounds=[(0.01, 0.99)], \n",
    "    tol=1e-5\n",
    ")\n",
    "\n",
    "optimal_threshold_ensemble = result_ensemble.x[0] if isinstance(result_ensemble.x, np.ndarray) else result_ensemble.x\n",
    "optimal_f1_ensemble = -result_ensemble.fun\n",
    "\n",
    "print(f\"\\n--- Ensemble F1 Optimization Results ---\")\n",
    "print(f\"Optimal Ensemble Threshold: {optimal_threshold_ensemble:.4f}\")\n",
    "print(f\"Maximized Ensemble F1-Score (OOF): {optimal_f1_ensemble:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3. Create Final Ensemble Test Probability\n",
    "# Note: test_probas is from your original LGBM run\n",
    "ensemble_test_probas = (test_probas + xgb_test_probas + cb_test_probas) / 3.0\n",
    "\n",
    "# 4.4. Convert to Hard Labels\n",
    "hard_labels_ensemble = np.where(\n",
    "    ensemble_test_probas >= optimal_threshold_ensemble, \n",
    "    'Left', \n",
    "    'Stayed'\n",
    ")\n",
    "\n",
    "# 4.5. Create and Save Submission\n",
    "submission_df_ensemble = pd.DataFrame({\n",
    "    'founder_id': test_ids,\n",
    "    'retention_status': hard_labels_ensemble \n",
    "})\n",
    "\n",
    "submission_df_ensemble.to_csv('ensemble_xgb_lgbm_cb_f1_submission.csv', index=False, encoding='utf-8', sep=',')\n",
    "\n",
    "print(\"\\nEnsemble Submission File 'ensemble_xgb_lgbm_cb_f1_submission.csv' created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
